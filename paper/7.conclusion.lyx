#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
In this work, we proposed a framework for generating source codes at a token
 level.
 We show that by using our network which first selects lines of similar
 patterns and then generates a new line accordingly, we can generate linewise
 source codes while preserving the patterns of previous lines, also at a
 high accuracy.
 Performance results show that our proposed models beat conventional methods
 used for generating sequences and thus can be applied to code autocompletion
 in scenarios where a user has to generate repetitive but slightly different
 lines of code.
 We also demonstrated how our model can benefit from using a selective copying
 mechanism by not having to resort to a large vocabulary size.
 Last of all, we presented visualizations which show that our model can
 learn the concepts of deciding when to selectively copying tokens from
 the source and query lines as well as generating new tokens from processed
 information.
 Our work opens up the possibility of a straightforward yet effective approach
 towards the complex task of source code autocompletion and generation without
 requiring handcrafted rules and structural information, and and can possibly
 be applied to many other tasks in the domain of software engineering.
\end_layout

\end_body
\end_document
